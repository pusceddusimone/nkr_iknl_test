{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9770748,"sourceType":"datasetVersion","datasetId":5980744}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q transformers datasets openpyxl scikit-learn seaborn joblib pandas lifelines XlsxWriter","metadata":{"_uuid":"e78542d6-f67b-4084-85d3-8cd3ad4c605d","_cell_guid":"e1e01ef0-1176-498b-b889-62ac412f3327","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-11-12T16:20:30.049694Z","iopub.execute_input":"2024-11-12T16:20:30.050810Z","iopub.status.idle":"2024-11-12T16:20:42.560615Z","shell.execute_reply.started":"2024-11-12T16:20:30.050764Z","shell.execute_reply":"2024-11-12T16:20:42.559246Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport numpy as np\nimport torch\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport logging\nfrom lifelines.utils import concordance_index\nfrom sklearn.model_selection import StratifiedKFold, KFold, train_test_split\nfrom sklearn.metrics import (\n    accuracy_score,\n    f1_score,\n    precision_score,\n    recall_score,\n    confusion_matrix,\n    roc_auc_score,\n    average_precision_score,\n    brier_score_loss,\n    classification_report,\n    mean_squared_error,\n    mean_absolute_error,\n    r2_score\n)\nfrom transformers import (AutoTokenizer, AutoModelForSequenceClassification,\n                          TrainingArguments, Trainer, EarlyStoppingCallback)\nimport datasets\nfrom datasets import Dataset\nimport joblib\nfrom joblib import Parallel, delayed\nimport gc\nfrom scipy import stats","metadata":{"_uuid":"b83ebca6-fb7e-4790-b51a-2cfbee25c99c","_cell_guid":"da5cd57f-f925-4f2c-8bb9-666817add87b","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-11-12T16:20:42.562727Z","iopub.execute_input":"2024-11-12T16:20:42.563115Z","iopub.status.idle":"2024-11-12T16:20:42.571477Z","shell.execute_reply.started":"2024-11-12T16:20:42.563078Z","shell.execute_reply":"2024-11-12T16:20:42.570544Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"base_path = \"/kaggle/input/nkr-iknl-breast-syntheticdata\"\nbase_output_path = \"/kaggle/working\"\nmodel_name = \"emilyalsentzer/Bio_ClinicalBERT\"\nmain_data_file = os.path.join(base_output_path, \"main_data.csv\")","metadata":{"_uuid":"29c4356b-1344-4119-a0d0-ed4b13526340","_cell_guid":"5fdb143c-8197-40fa-8c33-208319e39862","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-11-12T16:20:42.572853Z","iopub.execute_input":"2024-11-12T16:20:42.573233Z","iopub.status.idle":"2024-11-12T16:20:42.589088Z","shell.execute_reply.started":"2024-11-12T16:20:42.573199Z","shell.execute_reply":"2024-11-12T16:20:42.588218Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(model_name)","metadata":{"_uuid":"42bb8bcb-fc9b-4cad-86c8-4eaa91d8cfea","_cell_guid":"177f5288-1d56-4c61-936c-02a0d3c6d782","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-11-12T16:20:42.591292Z","iopub.execute_input":"2024-11-12T16:20:42.591621Z","iopub.status.idle":"2024-11-12T16:20:43.976037Z","shell.execute_reply.started":"2024-11-12T16:20:42.591588Z","shell.execute_reply":"2024-11-12T16:20:43.974851Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nprint(f\"Using device: {device}\")","metadata":{"_uuid":"fd9b0e81-951d-40a5-b354-72307b7540bd","_cell_guid":"6986a6f1-c30b-4055-824b-22279000b590","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-11-12T16:20:43.977275Z","iopub.execute_input":"2024-11-12T16:20:43.977610Z","iopub.status.idle":"2024-11-12T16:20:43.983060Z","shell.execute_reply.started":"2024-11-12T16:20:43.977570Z","shell.execute_reply":"2024-11-12T16:20:43.982014Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def apply_days_threshold(data, num_days):\n    data = data.copy()\n    data['converted_from_dead'] = 0\n\n    # Remove records where vit_stat == 0 and vit_stat_int < num_days\n    condition_remove = (data['vit_stat'] == 0) & (data['vit_stat_int'] < num_days)\n    data = data[~condition_remove]\n\n    # Convert records where vit_stat == 1 and vit_stat_int > num_days to vit_stat == 0\n    condition_convert = (data['vit_stat'] == 1) & (data['vit_stat_int'] > num_days)\n    data.loc[condition_convert, 'vit_stat'] = 0\n    data.loc[condition_convert, 'converted_from_dead'] = 1\n\n    return data","metadata":{"_uuid":"dc8bdc0e-4852-441f-ba5f-12090c6650a5","_cell_guid":"bf3c746e-39bb-4acf-a20c-165152b68fc6","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-11-12T16:20:43.984280Z","iopub.execute_input":"2024-11-12T16:20:43.984561Z","iopub.status.idle":"2024-11-12T16:20:43.995224Z","shell.execute_reply.started":"2024-11-12T16:20:43.984530Z","shell.execute_reply":"2024-11-12T16:20:43.994317Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def create_record_id(data):\n    if 'record_id' not in data.columns:\n        data = data.reset_index(drop=True).reset_index().rename(columns={'index': 'record_id'})\n    else:\n        data['record_id'] = data['record_id'].astype(str)\n    return data","metadata":{"_uuid":"060e5793-afa7-4a59-bcc3-078a8e26e129","_cell_guid":"7c20d80c-11e7-4331-9314-91c8c51f1da7","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-11-12T16:20:43.996315Z","iopub.execute_input":"2024-11-12T16:20:43.996664Z","iopub.status.idle":"2024-11-12T16:20:44.005987Z","shell.execute_reply.started":"2024-11-12T16:20:43.996618Z","shell.execute_reply":"2024-11-12T16:20:44.005010Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"feature_list = [\n        ('leeft', 'Age at incidence date'),\n        ('gesl', 'Gender'),\n        ('incjr', 'Year of incidence'),\n        ('tumsoort', 'Tumor species'),\n        ('diag_basis', 'Basis for diagnosis'),\n        ('topo', 'Topography excluding sub-localisation'),\n        ('topo_sublok', 'Topography including sub-localisation'),\n        ('later', 'Lateralisation'),\n        ('morf', 'Morphology'),\n        ('gedrag', 'Tumor behavior'),\n        ('diffgrad', 'Level of differentiation'),\n        ('ct', 'Clinical T (TNM)'),\n        ('cn', 'Clinical N (TNM)'),\n        ('cm', 'Clinical M (TNM)'),\n        ('pt', 'Pathological T (TNM)'),\n        ('pn', 'Pathological N (TNM)'),\n        ('pm', 'Pathological M (TNM)'),\n        ('stadium', 'Tumor stage (pTNM and cTNM)'),\n        ('cstadium', 'Clinical stage'),\n        ('pstadium', 'Pathological stage'),\n        ('ond_lymf', 'Number of regional lymph nodes examined'),\n        ('pos_lymf', 'Number of positive regional lymph nodes'),\n        ('er_stat', 'Oestrogen receptor status'),\n        ('pr_stat', 'Progesterone receptor status'),\n        ('her2_stat', 'HER2 status'),\n        ('dcis_comp', 'DCIS component present'),\n        ('multifoc', 'Multicentric/multifocal presence'),\n        ('tum_afm', 'Tumor size (mm)'),\n        ('swk', 'Sentinel node status'),\n        ('swk_uitslag', 'Sentinel node procedure result'),\n        ('mari', 'MARI procedure status'),\n        ('mari_uitslag', 'MARI procedure result'),\n        ('okd', 'Cerebral node dissection'),\n        ('org_chir', 'Surgery performed'),\n        ('uitgebr_chir_code', 'Expanded surgery code'),\n        ('dir_reconstr', 'Direct reconstruction'),\n        ('chemo', 'Chemotherapy'),\n        ('target', 'Targeted therapy'),\n        ('horm', 'Hormonal therapy'),\n        ('rt', 'Radiotherapy'),\n        ('meta_rt', 'Metastatic radiotherapy'),\n        ('meta_chir', 'Metastatic surgery'),\n    ]","metadata":{"_uuid":"dbdee0ce-9815-4e13-a760-01607454ca84","_cell_guid":"7943a85d-f871-48bf-87f2-db7408a52b80","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-11-12T16:20:44.007264Z","iopub.execute_input":"2024-11-12T16:20:44.007627Z","iopub.status.idle":"2024-11-12T16:20:44.017928Z","shell.execute_reply.started":"2024-11-12T16:20:44.007594Z","shell.execute_reply":"2024-11-12T16:20:44.017010Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def generate_classification_prompt(data):\n    def create_classification_prompt(row):\n        prompt_lines = [\"Patient Record:\"]\n        \n        for col, description in feature_list:\n            if col in data.columns:\n                value = row[col]\n                if pd.notnull(value):\n                    line = f\"- {description}: {value}\"\n                    prompt_lines.append(line)\n                # If the value is null (NaN), skip adding this line\n            # If the column does not exist in the DataFrame, skip adding this line\n        \n        prompt_lines.append(\"Based on this medical record, determine the patient's vital status and the time interval since their last examination.\")\n        prompt = '\\n'.join(prompt_lines)\n        return prompt\n    \n    data['classification_prompt'] = data.apply(create_classification_prompt, axis=1)\n    return data","metadata":{"_uuid":"c60c5f3e-2fe6-4154-a5cf-645ce2e8a1eb","_cell_guid":"f0aa4ca2-d9db-45e8-88ac-c73cff78ad1d","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-11-12T16:20:44.037294Z","iopub.execute_input":"2024-11-12T16:20:44.037650Z","iopub.status.idle":"2024-11-12T16:20:44.049751Z","shell.execute_reply.started":"2024-11-12T16:20:44.037617Z","shell.execute_reply":"2024-11-12T16:20:44.048912Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def generate_regression_prompt(data):\n    def create_regression_prompt(row):\n        prompt_lines = [\"Patient Record:\"]\n        \n        for col, description in feature_list:\n            if col in data.columns:\n                value = row[col]\n                if pd.notnull(value):\n                    line = f\"- {description}: {value}\"\n                    prompt_lines.append(line)\n                # If the value is null (NaN), skip adding this line\n            # If the column does not exist in the DataFrame, skip adding this line\n        \n        prompt_lines.append(\"Based on this medical record, predict the patient's time interval since their last examination in days.\")\n        prompt = '\\n'.join(prompt_lines)\n        return prompt\n    \n    data['regression_prompt'] = data.apply(create_regression_prompt, axis=1)\n    return data","metadata":{"_uuid":"f775ba38-cc2f-4372-84c2-c8e1009e3773","_cell_guid":"1dc5ff2f-cd84-4ff2-9fb9-24181671b958","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-11-12T16:20:44.050797Z","iopub.execute_input":"2024-11-12T16:20:44.051106Z","iopub.status.idle":"2024-11-12T16:20:44.064016Z","shell.execute_reply.started":"2024-11-12T16:20:44.051074Z","shell.execute_reply":"2024-11-12T16:20:44.063127Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def tokenize_classification_data(data, tokenizer, max_length=512):\n    tokenized = tokenizer(\n        data['classification_prompt'],\n        padding='max_length',\n        truncation=True,\n        max_length=max_length\n    )\n    return tokenized","metadata":{"_uuid":"62c3586f-c2f4-4185-99a7-c9aceb5d2539","_cell_guid":"5ed7a966-ebbb-48c6-8955-10fb8bfe016a","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-11-12T16:20:44.065343Z","iopub.execute_input":"2024-11-12T16:20:44.065734Z","iopub.status.idle":"2024-11-12T16:20:44.074802Z","shell.execute_reply.started":"2024-11-12T16:20:44.065691Z","shell.execute_reply":"2024-11-12T16:20:44.073908Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def tokenize_regression_data(data, tokenizer, max_length=512):\n    tokenized = tokenizer(\n        data['regression_prompt'].tolist(),\n        padding='max_length',\n        truncation=True,\n        max_length=max_length\n    )\n    return tokenized","metadata":{"_uuid":"658eb4fb-6828-468c-b260-64071801b77b","_cell_guid":"965f7540-42d7-4046-9d05-d0463d7d5517","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-11-12T16:20:44.075994Z","iopub.execute_input":"2024-11-12T16:20:44.076522Z","iopub.status.idle":"2024-11-12T16:20:44.084870Z","shell.execute_reply.started":"2024-11-12T16:20:44.076481Z","shell.execute_reply":"2024-11-12T16:20:44.083863Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def downsample_class_0(\n    data, \n    target_column='vit_stat', \n    majority_class=0, \n    minority_class=1, \n    priority_column='converted_from_dead'\n):\n    \n    majority_class_data = data[data[target_column] == majority_class].copy()\n    minority_class_data = data[data[target_column] == minority_class].copy()\n    \n    priority_data = majority_class_data[majority_class_data[priority_column] == 1].copy()\n    non_priority_data = majority_class_data[majority_class_data[priority_column] == 0].copy()\n    \n    desired_majority_size = len(minority_class_data)\n    \n    current_majority_size = len(majority_class_data)\n    \n    num_to_remove = current_majority_size - desired_majority_size\n    \n    if num_to_remove <= 0:\n        print(\"No downsampling needed. The majority class is already balanced or smaller than the minority class.\")\n        return data.copy()\n    \n    data_to_retain = []\n    \n    num_priority = len(priority_data)\n    \n    if num_to_remove <= num_priority:\n        priority_downsampled = priority_data.sample(n=num_to_remove, random_state=42)\n        priority_retained = priority_data.drop(priority_downsampled.index)\n        data_to_retain = [priority_retained, non_priority_data]\n        print(f\"Removed {num_to_remove} priority records (`{priority_column} == 1`) from the majority class.\")\n    else:\n        priority_downsampled = priority_data\n        remaining_to_remove = num_to_remove - num_priority\n        remaining_to_remove = min(remaining_to_remove, len(non_priority_data))\n        if remaining_to_remove > 0:\n            non_priority_downsampled = non_priority_data.sample(n=remaining_to_remove, random_state=42)\n            non_priority_retained = non_priority_data.drop(non_priority_downsampled.index)\n            data_to_retain = [non_priority_retained]\n            print(f\"Removed all {num_priority} priority records (`{priority_column} == 1`) and {remaining_to_remove} non-priority records (`{priority_column} == 0`) from the majority class.\")\n        else:\n            data_to_retain = [non_priority_data]\n            print(f\"Removed all {num_priority} priority records (`{priority_column} == 1`) from the majority class.\")\n    \n    majority_downsampled = pd.concat(data_to_retain).copy()\n    \n    downsampled_data = pd.concat([majority_downsampled, minority_class_data]).sample(frac=1, random_state=42).reset_index(drop=True)\n    \n    print(f\"\\nOriginal class distribution:\\n{data[target_column].value_counts()}\")\n    print(f\"\\nNew class distribution after downsampling:\\n{downsampled_data[target_column].value_counts()}\")\n    print(f\"\\nNumber of priority records removed: {len(priority_downsampled)}\")\n    if 'non_priority_downsampled' in locals():\n        print(f\"Number of non-priority records removed: {remaining_to_remove}\")\n    \n    return downsampled_data","metadata":{"_uuid":"1c4f2a26-7f20-462e-a169-786fd4a0f5c5","_cell_guid":"144d9a0c-3246-441d-8aac-8ba32c34535a","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-11-12T16:20:44.086400Z","iopub.execute_input":"2024-11-12T16:20:44.086854Z","iopub.status.idle":"2024-11-12T16:20:44.101449Z","shell.execute_reply.started":"2024-11-12T16:20:44.086811Z","shell.execute_reply":"2024-11-12T16:20:44.100515Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def load_and_preprocess_classification_data(num_days, num_folds=5, max_length=256):\n    data_path = os.path.join(base_path, \"NKR_IKNL_breast_syntheticdata.csv\")\n    main_data = pd.read_csv(data_path, delimiter=\";\")\n\n    if (os.path.exists(main_data_file)):\n        main_data = pd.read_csv(main_data_file)\n    else:\n        main_data = apply_days_threshold(main_data, num_days)\n        main_data = downsample_class_0(main_data)\n        main_data = main_data.sample(frac=1, random_state=42).reset_index(drop=True)\n        main_data = create_record_id(main_data)\n        main_data.to_csv(main_data_file, index=False)\n\n    main_data = generate_classification_prompt(main_data)\n\n    train_data, test_data = train_test_split(\n        main_data,\n        test_size=0.2,\n        stratify=main_data['vit_stat'],\n        random_state=42\n    )\n\n    test_file = os.path.join(base_output_path, \"classification_test.csv\")\n    test_data.to_csv(test_file, index=False)\n    print(f\"Hold-out test set saved with shape: {test_data.shape}\")\n\n    train_data_folds = {}\n    eval_data_folds = {}\n    all_folds_exist = True\n\n    for fold in range(1, num_folds + 1):\n        train_file = os.path.join(base_output_path, f\"classification_train_{fold}.csv\")\n        eval_file = os.path.join(base_output_path, f\"classification_eval_{fold}.csv\")\n\n        if os.path.exists(train_file) and os.path.exists(eval_file):\n            train_data_fold = pd.read_csv(train_file)\n            eval_data_fold = pd.read_csv(eval_file)\n            train_data_folds[fold] = train_data_fold\n            eval_data_folds[fold] = eval_data_fold\n            print(f\"Loaded existing data for fold {fold} - Train: {train_data_fold.shape}, Eval: {eval_data_fold.shape}\")\n        else:\n            all_folds_exist = False\n            print(f\"Files for fold {fold} are missing. Need to generate all folds.\")\n            break \n\n    if not all_folds_exist:\n        print(f\"Splitting main training data into {num_folds} folds.\")\n        skf = StratifiedKFold(n_splits=num_folds, shuffle=True, random_state=42)\n        for fold_index, (train_idx, eval_idx) in enumerate(skf.split(train_data, train_data['vit_stat']), start=1):\n            train_data_split = train_data.iloc[train_idx].reset_index(drop=True)\n            eval_data_split = train_data.iloc[eval_idx].reset_index(drop=True)\n\n            train_split_file = os.path.join(base_output_path, f\"classification_train_{fold_index}.csv\")\n            eval_split_file = os.path.join(base_output_path, f\"classification_eval_{fold_index}.csv\")\n            train_data_split.to_csv(train_split_file, index=False)\n            eval_data_split.to_csv(eval_split_file, index=False)\n\n            train_data_folds[fold_index] = train_data_split\n            eval_data_folds[fold_index] = eval_data_split\n\n        print(f\"Cross-validation data saved for all {num_folds} folds.\")\n\n    tokenized_train_folds = {}\n    tokenized_eval_folds = {}\n    \n    for fold_index in train_data_folds.keys():\n        print(f\"Tokenizing fold {fold_index} - Training data\")\n        train_dataset = Dataset.from_pandas(train_data_folds[fold_index])\n        tokenized_train = train_dataset.map(\n            lambda x: tokenize_classification_data(x, tokenizer, max_length=max_length),\n            batched=True,\n            batch_size=1000,\n            num_proc=4,\n            remove_columns=['classification_prompt']\n        )\n        tokenized_train = tokenized_train.rename_column(\"vit_stat\", \"labels\")\n        tokenized_train.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])\n\n        print(f\"Tokenizing fold {fold_index} - Evaluation data\")\n        eval_dataset = Dataset.from_pandas(eval_data_folds[fold_index])\n        tokenized_eval = eval_dataset.map(\n            lambda x: tokenize_classification_data(x, tokenizer, max_length=max_length),\n            batched=True,\n            batch_size=1000,\n            num_proc=4,\n            remove_columns=['classification_prompt']\n        )\n        tokenized_eval = tokenized_eval.rename_column(\"vit_stat\", \"labels\")\n        tokenized_eval.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])\n\n        tokenized_train_folds[fold_index] = tokenized_train\n        tokenized_eval_folds[fold_index] = tokenized_eval\n\n    return tokenized_train_folds, tokenized_eval_folds, test_data","metadata":{"_uuid":"f907690d-b703-4610-ab3a-b95740007811","_cell_guid":"d99a9101-8f12-40d0-a837-7ef5add60673","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-11-12T16:20:44.102974Z","iopub.execute_input":"2024-11-12T16:20:44.103432Z","iopub.status.idle":"2024-11-12T16:20:44.124399Z","shell.execute_reply.started":"2024-11-12T16:20:44.103383Z","shell.execute_reply":"2024-11-12T16:20:44.123362Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_classification_data_folds, eval_classification_data_folds, test_data = load_and_preprocess_classification_data(1825)","metadata":{"_uuid":"ba5703a4-e6bc-49b4-aa69-ae6da9c5d4ba","_cell_guid":"ca935c17-d389-421e-b7e4-b837037914d8","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-11-12T16:20:44.125627Z","iopub.execute_input":"2024-11-12T16:20:44.125971Z","iopub.status.idle":"2024-11-12T16:21:41.633727Z","shell.execute_reply.started":"2024-11-12T16:20:44.125905Z","shell.execute_reply":"2024-11-12T16:21:41.632497Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def compute_metrics_classifier(p):\n    preds = np.argmax(p.predictions, axis=1)\n    labels = p.label_ids\n    acc = accuracy_score(labels, preds)\n\n    probs = torch.softmax(torch.tensor(p.predictions), dim=1).numpy()\n    pos_probs = probs[:, 1]\n\n    brier = brier_score_loss(labels, pos_probs)\n\n    precision = precision_score(labels, preds, average='weighted', zero_division=0)\n    recall = recall_score(labels, preds, average='weighted', zero_division=0)\n    f1 = f1_score(labels, preds, average='weighted', zero_division=0)\n    roc_auc = roc_auc_score(labels, pos_probs, average='weighted') if len(np.unique(labels)) > 1 else float('nan')\n    pr_auc = average_precision_score(labels, pos_probs, average='weighted') if len(np.unique(labels)) > 1 else float('nan')\n\n    combined_score = (f1 * 0.5) + (roc_auc * 0.3) + (pr_auc * 0.2)\n\n    return {\n        'accuracy': acc,\n        'brier_score': brier,\n        'precision': precision,\n        'recall': recall,\n        'f1_score': f1,\n        'roc_auc': roc_auc,\n        'pr_auc': pr_auc,\n        'combined_score': combined_score\n    }","metadata":{"_uuid":"3f06de1f-1ec6-4abd-a97c-25ea853849b2","_cell_guid":"85b5eb5d-43b7-4044-b120-a854ef50451d","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-11-12T16:21:41.636265Z","iopub.execute_input":"2024-11-12T16:21:41.636609Z","iopub.status.idle":"2024-11-12T16:21:41.647831Z","shell.execute_reply.started":"2024-11-12T16:21:41.636574Z","shell.execute_reply":"2024-11-12T16:21:41.646769Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def fine_tune_classifier(tokenized_train_folds, tokenized_eval_folds, output_dir, num_labels=2, epochs=5):\n    ## REMEMBER TO CHANGE MAX LENGTH FROM 256 TO 512\n    initial_best_model_path = os.path.join(output_dir, \"best_model\")\n\n    if os.path.exists(initial_best_model_path) and os.listdir(initial_best_model_path):\n        print(f\"Found existing model at {initial_best_model_path}. Loading the model instead of retraining.\")\n        best_model = AutoModelForSequenceClassification.from_pretrained(initial_best_model_path)\n        return best_model\n    \n    best_combined_score = float('-inf')\n    best_model_dir = None\n    \n    os.makedirs(output_dir, exist_ok=True)\n    \n    for fold_index, train_dataset in tokenized_train_folds.items():\n        eval_dataset = tokenized_eval_folds[fold_index]\n\n        print(f\"\\nStarting training for Fold {fold_index}\")\n\n        model = AutoModelForSequenceClassification.from_pretrained(\n            model_name,\n            num_labels=num_labels\n        ).to(device)\n\n        fold_output_dir = os.path.join(output_dir, f\"fold_{fold_index}\")\n        os.makedirs(fold_output_dir, exist_ok=True)\n\n        training_args = TrainingArguments(\n            output_dir=fold_output_dir,\n            eval_strategy=\"epoch\",\n            save_strategy=\"epoch\",\n            learning_rate=2e-5,\n            per_device_train_batch_size=16,\n            per_device_eval_batch_size=16,\n            num_train_epochs=epochs,\n            weight_decay=0.01,\n            logging_strategy='no',\n            logging_steps=0,\n            logging_dir=None,\n            report_to=\"none\",\n            fp16=torch.cuda.is_available(),\n            dataloader_num_workers=4,\n            load_best_model_at_end=True,\n            metric_for_best_model=\"combined_score\",\n            save_total_limit=1,\n            gradient_accumulation_steps=2,\n        )\n\n        trainer = Trainer(\n            model=model,\n            args=training_args,\n            train_dataset=train_dataset,\n            eval_dataset=eval_dataset,\n            compute_metrics=compute_metrics_classifier,\n            callbacks=[EarlyStoppingCallback(early_stopping_patience=2)]\n        )\n\n        trainer.train()\n        metrics = trainer.evaluate()\n        print(f\"Fold {fold_index} - Evaluation Metrics:\", metrics)\n\n        if metrics[\"eval_combined_score\"] > best_combined_score:\n            best_combined_score = metrics[\"eval_combined_score\"]\n            best_model_dir = fold_output_dir\n            trainer.save_model(initial_best_model_path)\n            print(f\"New best model found in fold {fold_index} with combined score: {best_combined_score}\")\n\n    if best_model_dir is not None:\n        print(f\"\\nLoading the best model from {initial_best_model_path}\")\n        best_model = AutoModelForSequenceClassification.from_pretrained(initial_best_model_path)\n        return best_model\n    else:\n        raise ValueError(\"No model was trained. Please check your training data and configuration.\")","metadata":{"_uuid":"7b1b34ea-443c-4dfe-8044-e7b364b51df0","_cell_guid":"04eec7a4-d65f-4c44-bbdf-6b1a225d2568","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-11-12T16:21:41.649049Z","iopub.execute_input":"2024-11-12T16:21:41.649373Z","iopub.status.idle":"2024-11-12T16:21:41.667221Z","shell.execute_reply.started":"2024-11-12T16:21:41.649322Z","shell.execute_reply":"2024-11-12T16:21:41.666361Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"best_model = fine_tune_classifier(\n    tokenized_train_folds=train_classification_data_folds,\n    tokenized_eval_folds=eval_classification_data_folds,\n    output_dir=base_output_path,\n    num_labels=2,\n    epochs=5\n)","metadata":{"_uuid":"0d216b8d-180c-4ef1-ae12-4f20ef4d5cc3","_cell_guid":"8cbf0ba3-a2a4-4b37-98bb-be0ab1939cfd","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-11-12T16:21:41.668351Z","iopub.execute_input":"2024-11-12T16:21:41.668657Z","iopub.status.idle":"2024-11-12T16:21:41.772651Z","shell.execute_reply.started":"2024-11-12T16:21:41.668624Z","shell.execute_reply":"2024-11-12T16:21:41.771645Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def predict_vit_stat(model, tokenizer, data, max_length = 512):\n    encodings = tokenizer(list(data['classification_prompt']), truncation=True, padding=True, max_length = max_length)\n    dataset = Dataset.from_dict({**encodings})\n    \n    trainer = Trainer(model=model, args=TrainingArguments(output_dir=\"./results\", report_to=\"none\"))\n    predictions = trainer.predict(dataset)\n    pred_labels = np.argmax(predictions.predictions, axis=1)\n    \n    return pred_labels","metadata":{"_uuid":"09e989d5-2dd3-4d1a-9ed6-736c260e991f","_cell_guid":"e4810d5e-278c-4994-af47-f3b1de33e8fb","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-11-12T16:21:41.774499Z","iopub.execute_input":"2024-11-12T16:21:41.774811Z","iopub.status.idle":"2024-11-12T16:21:41.780899Z","shell.execute_reply.started":"2024-11-12T16:21:41.774779Z","shell.execute_reply":"2024-11-12T16:21:41.779879Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"predicted_labels = predict_vit_stat(best_model, tokenizer, test_data, max_length = 256)\n\ntest_data['predicted_vit_stat'] = predicted_labels\nprint(test_data[['classification_prompt', 'vit_stat', 'predicted_vit_stat']])","metadata":{"_uuid":"69710987-a029-4fdf-9a68-bac8d34952fc","_cell_guid":"f4e16ff9-98df-4c76-8dc3-a0e8262b9946","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-11-12T16:21:41.781930Z","iopub.execute_input":"2024-11-12T16:21:41.782259Z","iopub.status.idle":"2024-11-12T16:22:14.399937Z","shell.execute_reply.started":"2024-11-12T16:21:41.782227Z","shell.execute_reply":"2024-11-12T16:22:14.398878Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def save_classification_metrics_to_excel(\n    true_labels, \n    pred_labels, \n    train_classification_data_folds, \n    eval_classification_data_folds, \n    test_data, \n    filename=\"classification_results.xlsx\"\n):\n    columns_to_exclude = ['input_ids', 'token_type_ids', 'attention_mask', 'classification_prompt']\n\n    if isinstance(test_data, Dataset):\n        test_df = test_data.to_pandas()\n    elif isinstance(test_data, pd.DataFrame):\n        test_df = test_data.copy()\n    else:\n        raise TypeError(\"test_data must be a pandas DataFrame or a Hugging Face Dataset.\")\n\n    test_df.drop(columns=[col for col in columns_to_exclude if col in test_df.columns], inplace=True)\n\n    cm = confusion_matrix(true_labels, pred_labels)\n    cm_df = pd.DataFrame(\n        cm, \n        index=[f\"Actual_{i}\" for i in range(len(cm))], \n        columns=[f\"Predicted_{i}\" for i in range(len(cm))]\n    )\n\n    accuracy = accuracy_score(true_labels, pred_labels)\n    precision = precision_score(true_labels, pred_labels, average='weighted', zero_division=0)\n    recall = recall_score(true_labels, pred_labels, average='weighted', zero_division=0)\n    f1 = f1_score(true_labels, pred_labels, average='weighted', zero_division=0)\n\n    classification_rep = classification_report(true_labels, pred_labels, output_dict=True, zero_division=0)\n    classification_rep_df = pd.DataFrame(classification_rep).transpose()\n\n    with pd.ExcelWriter(filename, engine='xlsxwriter') as writer:\n        cm_df.to_excel(writer, sheet_name=\"Confusion Matrix\", index=True)\n        \n        metrics_df = pd.DataFrame({\n            \"Metric\": [\"Accuracy\", \"Precision\", \"Recall\", \"F1 Score\"],\n            \"Value\": [accuracy, precision, recall, f1]\n        })\n        metrics_df.to_excel(writer, sheet_name=\"Overall Metrics\", index=False)\n        \n        classification_rep_df.to_excel(writer, sheet_name=\"Classification Report\")\n        \n        def save_folds(folds_dict, fold_type=\"Train\"):\n            for fold_num, fold in folds_dict.items():\n                sheet_name = f\"{fold_type} Fold {fold_num}\"\n                \n                if isinstance(fold, Dataset):\n                    fold_df = fold.to_pandas()\n                elif isinstance(fold, pd.DataFrame):\n                    fold_df = fold.copy()\n                else:\n                    print(f\"Skipping {sheet_name}: Unsupported data type {type(fold)}.\")\n                    continue\n                \n                fold_df.drop(columns=[col for col in columns_to_exclude if col in fold_df.columns], inplace=True)\n                \n                try:\n                    fold_df.to_excel(writer, sheet_name=sheet_name, index=False)\n                    print(f\"Saved {sheet_name}\")\n                except Exception as e:\n                    print(f\"Error saving {sheet_name}: {e}\")\n\n        save_folds(train_classification_data_folds, fold_type=\"Train\")\n        \n        save_folds(eval_classification_data_folds, fold_type=\"Eval\")\n        \n        try:\n            test_df.to_excel(writer, sheet_name=\"Test Data\", index=False)\n            print(\"Saved Test Data\")\n        except Exception as e:\n            print(f\"Error saving Test Data: {e}\")\n    \n    print(f\"All metrics and data have been saved to '{filename}'.\")","metadata":{"_uuid":"f7ffa281-62cd-49eb-96f9-92823b06ad2d","_cell_guid":"d8597ada-d765-4983-bd6b-e5c169f98b87","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-11-12T16:22:14.401680Z","iopub.execute_input":"2024-11-12T16:22:14.402269Z","iopub.status.idle":"2024-11-12T16:22:14.420211Z","shell.execute_reply.started":"2024-11-12T16:22:14.402215Z","shell.execute_reply":"2024-11-12T16:22:14.419306Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"true_labels = test_data['vit_stat']\npred_labels = test_data['predicted_vit_stat']\nsave_classification_metrics_to_excel(true_labels, pred_labels, train_classification_data_folds, eval_classification_data_folds, test_data)","metadata":{"_uuid":"ec883ba3-d5dd-4dff-8ce3-12bf9210fa21","_cell_guid":"64ae4989-445d-4b52-a612-cb5967693886","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-11-12T16:22:14.421792Z","iopub.execute_input":"2024-11-12T16:22:14.422830Z","iopub.status.idle":"2024-11-12T16:23:30.963466Z","shell.execute_reply.started":"2024-11-12T16:22:14.422776Z","shell.execute_reply":"2024-11-12T16:23:30.962425Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"processed_main_data = pd.DataFrame()\nif(os.path.exists(main_data_file)):\n    processed_main_data = pd.read_csv(main_data_file)","metadata":{"_uuid":"de12f466-dafd-4a0d-ae74-4aa2866dd295","_cell_guid":"35e97b00-638c-497d-af0b-b3122f0e4578","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-11-12T16:23:30.965716Z","iopub.execute_input":"2024-11-12T16:23:30.966502Z","iopub.status.idle":"2024-11-12T16:23:31.091054Z","shell.execute_reply.started":"2024-11-12T16:23:30.966450Z","shell.execute_reply":"2024-11-12T16:23:31.090175Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def preprocess_regression_data(data, test_data_with_predictions):\n    train_data_regression = data[data['vit_stat'] == 1].copy()\n    test_data_regression = test_data_with_predictions[test_data_with_predictions['predicted_vit_stat'] == 1].copy()\n\n    if 'classification_prompt' in test_data_regression.columns:\n        test_data_regression = test_data_regression.drop(columns=['classification_prompt'])\n\n    # Remove any records from train_data_regression that are in test_data_regression\n    test_record_ids = test_data_regression['record_id'].unique()\n    train_data_regression = train_data_regression[~train_data_regression['record_id'].isin(test_record_ids)].copy()\n\n    # Create second test set: subset of test_data_regression where 'vit_stat' == 1\n    test_data_regression_real1s = test_data_regression[test_data_regression['vit_stat'] == 1].copy()\n\n    train_data_regression.to_csv(os.path.join(base_output_path, \"test_data_regression.csv\"), index=False)\n    test_data_regression.to_csv(os.path.join(base_output_path, \"test_data_regression.csv\"), index=False)\n    test_data_regression_real1s.to_csv(os.path.join(base_output_path, \"test_data_regression_real1s.csv\"), index=False)\n\n\n    # Generate regression prompts\n    train_data_regression = generate_regression_prompt(train_data_regression)\n    test_data_regression = generate_regression_prompt(test_data_regression)\n    test_data_regression_real1s = generate_regression_prompt(test_data_regression_real1s)\n\n    # Tokenize the data\n    train_encodings = tokenize_regression_data(train_data_regression, tokenizer)\n    test_encodings = tokenize_regression_data(test_data_regression, tokenizer)\n    test_real1s_encodings = tokenize_regression_data(test_data_regression_real1s, tokenizer)\n\n    # Create Hugging Face Datasets\n    train_dataset = datasets.Dataset.from_dict({\n        'input_ids': train_encodings['input_ids'],\n        'attention_mask': train_encodings['attention_mask'],\n        'labels': train_data_regression['vit_stat_int'].astype(float),\n        'record_id': train_data_regression['record_id'].tolist()\n    })\n\n    test_dataset = datasets.Dataset.from_dict({\n        'input_ids': test_encodings['input_ids'],\n        'attention_mask': test_encodings['attention_mask'],\n        'labels': test_data_regression['vit_stat_int'].astype(float),\n        'record_id': test_data_regression['record_id'].tolist()\n    })\n\n    test_dataset_real1s = datasets.Dataset.from_dict({\n        'input_ids': test_real1s_encodings['input_ids'],\n        'attention_mask': test_real1s_encodings['attention_mask'],\n        'labels': test_data_regression_real1s['vit_stat_int'].astype(float),\n        'record_id': test_data_regression_real1s['record_id'].tolist()\n    })\n\n    # Set format for PyTorch\n    columns = ['input_ids', 'attention_mask', 'labels']\n    train_dataset.set_format(type='torch', columns=columns)\n    test_dataset.set_format(type='torch', columns=columns)\n    test_dataset_real1s.set_format(type='torch', columns=columns)\n\n    print(f\"Training set size: {train_dataset.shape[0]}\")\n    print(f\"Test set size (predicted 1s): {test_dataset.shape[0]}\")\n    print(f\"Test set size (true positives): {test_dataset_real1s.shape[0]}\")\n\n    return train_dataset, test_dataset, test_dataset_real1s","metadata":{"_uuid":"e1bde488-148b-4e73-9319-f55010786f5d","_cell_guid":"40f8f504-9d54-474e-acd4-5d098bc02071","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-11-12T17:04:07.519445Z","iopub.execute_input":"2024-11-12T17:04:07.520573Z","iopub.status.idle":"2024-11-12T17:04:07.540666Z","shell.execute_reply.started":"2024-11-12T17:04:07.520517Z","shell.execute_reply":"2024-11-12T17:04:07.539476Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_data_regression, test_data_regression, test_data_regression_real1s = preprocess_regression_data(processed_main_data, test_data)","metadata":{"_uuid":"edb0e8fe-d51e-4913-8c7c-643a0d983ebf","_cell_guid":"f3c9e9c6-1366-4183-be0f-c97ef6f1b3d5","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-11-12T17:04:10.342509Z","iopub.execute_input":"2024-11-12T17:04:10.343574Z","iopub.status.idle":"2024-11-12T17:04:22.379843Z","shell.execute_reply.started":"2024-11-12T17:04:10.343516Z","shell.execute_reply":"2024-11-12T17:04:22.378649Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def compute_metrics_regression(p):\n    preds = p.predictions.squeeze()\n    labels = p.label_ids.squeeze()\n\n    if preds.ndim > 1:\n        preds = preds.reshape(-1)\n    if labels.ndim > 1:\n        labels = labels.reshape(-1)\n\n    mse = mean_squared_error(labels, preds)\n    mae = mean_absolute_error(labels, preds)\n    rmse = np.sqrt(mse)\n    r2 = r2_score(labels, preds)\n\n    return {\n        'mse': mse,\n        'mae': mae,\n        'rmse': rmse,\n        'r2': r2\n    }","metadata":{"_uuid":"64b62fe6-4b2a-4889-84c5-267289a48878","_cell_guid":"2e60f291-bc2b-488e-99aa-be896511449a","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-11-12T16:25:56.466809Z","iopub.execute_input":"2024-11-12T16:25:56.467238Z","iopub.status.idle":"2024-11-12T16:25:56.474247Z","shell.execute_reply.started":"2024-11-12T16:25:56.467197Z","shell.execute_reply":"2024-11-12T16:25:56.473186Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def fine_tune_regressor(train_dataset, eval_dataset, output_dir, epochs=5):\n    model_save_path = os.path.join(output_dir, \"best_regression_model\")\n\n    if os.path.exists(model_save_path) and os.listdir(model_save_path):\n        print(f\"Found existing regression model at {model_save_path}. Loading the model instead of retraining.\")\n        model = AutoModelForSequenceClassification.from_pretrained(model_save_path)\n        return model\n\n    os.makedirs(output_dir, exist_ok=True)\n\n    model = AutoModelForSequenceClassification.from_pretrained(\n        model_name,\n        num_labels=1,\n        problem_type=\"regression\"\n    ).to(device)\n\n    training_args = TrainingArguments(\n        output_dir=output_dir,\n        eval_strategy=\"epoch\",\n        save_strategy=\"epoch\",\n        learning_rate=2e-5,\n        per_device_train_batch_size=16,\n        per_device_eval_batch_size=16,\n        num_train_epochs=epochs,\n        weight_decay=0.01,\n        logging_strategy='epoch',\n        logging_steps=0,\n        logging_dir=None,\n        report_to=\"none\",\n        fp16=torch.cuda.is_available(),\n        dataloader_num_workers=4,\n        load_best_model_at_end=True,\n        metric_for_best_model=\"rmse\",\n        greater_is_better=False,\n        save_total_limit=1,\n        gradient_accumulation_steps=2,\n    )\n\n    trainer = Trainer(\n        model=model,\n        args=training_args,\n        train_dataset=train_dataset,\n        eval_dataset=eval_dataset,\n        compute_metrics=compute_metrics_regression,\n        callbacks=[EarlyStoppingCallback(early_stopping_patience=2)]\n    )\n\n    trainer.train()\n    metrics = trainer.evaluate()\n    print(\"Evaluation Metrics:\", metrics)\n\n    # Save the model\n    trainer.save_model(model_save_path)\n    print(f\"Regression model saved at {model_save_path}\")\n\n    return model","metadata":{"_uuid":"f957e19e-e635-4469-b0d2-eb0e0510aac1","_cell_guid":"b8c70e80-030f-4061-a87f-7eaa2804d1a5","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-11-12T16:26:00.252333Z","iopub.execute_input":"2024-11-12T16:26:00.252906Z","iopub.status.idle":"2024-11-12T16:26:00.267584Z","shell.execute_reply.started":"2024-11-12T16:26:00.252851Z","shell.execute_reply":"2024-11-12T16:26:00.266035Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_test_split = train_data_regression.train_test_split(test_size=0.2, seed=42)\nsplit_train_data_regression = train_test_split['train']\neval_data = train_test_split['test']","metadata":{"_uuid":"e95aa266-a317-4d81-b08f-7fb86cfdda5f","_cell_guid":"40aaa02f-ae48-4f0d-ae19-5b86c9c00dad","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-11-12T16:26:02.000917Z","iopub.execute_input":"2024-11-12T16:26:02.001744Z","iopub.status.idle":"2024-11-12T16:26:02.018687Z","shell.execute_reply.started":"2024-11-12T16:26:02.001698Z","shell.execute_reply":"2024-11-12T16:26:02.017666Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"best_regressor_model = fine_tune_regressor(\n    train_dataset=split_train_data_regression,\n    eval_dataset=eval_data,\n    output_dir=base_output_path,\n    epochs=5\n)","metadata":{"_uuid":"2748a717-6dce-47b5-8235-8ec6a74d4d91","_cell_guid":"cf82c70d-dabb-4fca-a9ef-8a40107991ca","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-11-12T16:26:04.623156Z","iopub.execute_input":"2024-11-12T16:26:04.623830Z","iopub.status.idle":"2024-11-12T16:52:40.051286Z","shell.execute_reply.started":"2024-11-12T16:26:04.623791Z","shell.execute_reply":"2024-11-12T16:52:40.049966Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def predict_vit_stat_int(model, data):\n    if 'labels' in data.column_names:\n        data_for_prediction = data.remove_columns(['labels'])\n    else:\n        data_for_prediction = data\n\n    data_for_prediction.set_format(type='torch', columns=['input_ids', 'attention_mask'])\n\n    trainer = Trainer(\n        model=model,\n        args=TrainingArguments(\n            output_dir=\"./results\",\n            per_device_eval_batch_size=16,\n            report_to=\"none\",\n            dataloader_num_workers=4\n        )\n    )\n\n    # Get predictions\n    predictions = trainer.predict(data_for_prediction)\n\n    # For regression, predictions.predictions is of shape (num_samples, 1)\n    pred_values = predictions.predictions.squeeze()\n\n    return pred_values","metadata":{"_uuid":"870443cc-a9b7-4525-a95f-35b3d3ffea29","_cell_guid":"30a131f0-43ac-4659-b59b-0391fabe6ae1","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-11-12T16:23:32.968020Z","iopub.status.idle":"2024-11-12T16:23:32.968363Z","shell.execute_reply.started":"2024-11-12T16:23:32.968187Z","shell.execute_reply":"2024-11-12T16:23:32.968205Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"predicted_vit_stat_int_test = predict_vit_stat_int(\n    model=best_regressor_model,\n    data=test_data_regression\n)\n\n# Evaluate performance\ntrue_vit_stat_int = np.array(test_data_regression['labels'])\npredicted_vit_stat_int = predicted_vit_stat_int_test\n\nmse = mean_squared_error(true_vit_stat_int, predicted_vit_stat_int)\nmae = mean_absolute_error(true_vit_stat_int, predicted_vit_stat_int)\nrmse = np.sqrt(mse)\nr2 = r2_score(true_vit_stat_int, predicted_vit_stat_int)\n\nprint(\"Performance on test_data_regression:\")\nprint(f\"MSE: {mse:.2f}\")\nprint(f\"MAE: {mae:.2f}\")\nprint(f\"RMSE: {rmse:.2f}\")\nprint(f\"R2 Score: {r2:.4f}\")\n\n# Predict on test_data_regression_real1s\npredicted_vit_stat_int_real1s = predict_vit_stat_int(\n    model=best_regressor_model,\n    data=test_data_regression_real1s\n)\n\n# Evaluate performance\ntrue_vit_stat_int_real1s = np.array(test_data_regression_real1s['labels'])\npredicted_vit_stat_int = predicted_vit_stat_int_real1s\n\nmse_real1s = mean_squared_error(true_vit_stat_int_real1s, predicted_vit_stat_int)\nmae_real1s = mean_absolute_error(true_vit_stat_int_real1s, predicted_vit_stat_int)\nrmse_real1s = np.sqrt(mse_real1s)\nr2_real1s = r2_score(true_vit_stat_int_real1s, predicted_vit_stat_int)\n\nprint(\"\\nPerformance on test_data_regression_real1s (True Positives):\")\nprint(f\"MSE: {mse_real1s:.2f}\")\nprint(f\"MAE: {mae_real1s:.2f}\")\nprint(f\"RMSE: {rmse_real1s:.2f}\")\nprint(f\"R2 Score: {r2_real1s:.4f}\")","metadata":{"_uuid":"b77e5128-3c73-4f60-b3dd-dc0de8569c64","_cell_guid":"d9172f0b-8952-47dc-baca-c74f4ba96a07","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-11-12T17:02:22.889537Z","iopub.execute_input":"2024-11-12T17:02:22.890595Z","iopub.status.idle":"2024-11-12T17:03:06.799164Z","shell.execute_reply.started":"2024-11-12T17:02:22.890550Z","shell.execute_reply":"2024-11-12T17:03:06.798025Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def save_regression_metrics_to_excel(\n    train_dataset,\n    eval_dataset,\n    test_dataset,\n    test_dataset_real1s,\n    predicted_vit_stat_int_test,\n    predicted_vit_stat_int_real1s,\n    filename=\"regression_results.xlsx\"\n):\n    # Compute regression metrics for test_data_regression\n    true_vit_stat_int_test = np.array(test_dataset['labels'])\n    predicted_vit_stat_int_test = np.array(predicted_vit_stat_int_test)\n    mse_test = mean_squared_error(true_vit_stat_int_test, predicted_vit_stat_int_test)\n    mae_test = mean_absolute_error(true_vit_stat_int_test, predicted_vit_stat_int_test)\n    rmse_test = np.sqrt(mse_test)\n    r2_test = r2_score(true_vit_stat_int_test, predicted_vit_stat_int_test)\n\n    # Compute regression metrics for test_data_regression_real1s\n    true_vit_stat_int_real1s = np.array(test_dataset_real1s['labels'])\n    predicted_vit_stat_int_real1s = np.array(predicted_vit_stat_int_real1s)\n    mse_real1s = mean_squared_error(true_vit_stat_int_real1s, predicted_vit_stat_int_real1s)\n    mae_real1s = mean_absolute_error(true_vit_stat_int_real1s, predicted_vit_stat_int_real1s)\n    rmse_real1s = np.sqrt(mse_real1s)\n    r2_real1s = r2_score(true_vit_stat_int_real1s, predicted_vit_stat_int_real1s)\n\n    # Create DataFrame with regression metrics\n    metrics_df = pd.DataFrame({\n        \"Dataset\": [\"Test Data (Predicted 1s)\", \"Test Data (True Positives)\"],\n        \"RMSE\": [rmse_test, rmse_real1s],\n        \"R2 Score\": [r2_test, r2_real1s]\n    })\n\n    # Load datasets from CSV files\n    train_data_file = os.path.join(base_output_path, \"train_data_regression.csv\")\n    test_data_file = os.path.join(base_output_path, \"test_data_regression.csv\")\n    test_real1s_file = os.path.join(base_output_path, \"test_data_regression_real1s.csv\")\n\n    train_df = pd.read_csv(train_data_file)\n    test_df = pd.read_csv(test_data_file)\n    test_real1s_df = pd.read_csv(test_real1s_file)\n\n    # Convert eval_dataset to DataFrame and merge with train_df to get full data\n    eval_df = eval_dataset.to_pandas()\n    eval_df['record_id'] = eval_df['record_id'].astype(int)\n    train_df['record_id'] = train_df['record_id'].astype(int)\n    eval_full_df = pd.merge(eval_df, train_df, on='record_id', how='left')\n\n    # Merge predictions into test_df\n    test_df['record_id'] = test_df['record_id'].astype(int)\n    test_dataset_record_ids = [int(rid) for rid in test_dataset['record_id']]\n    pred_df = pd.DataFrame({\n        'record_id': test_dataset_record_ids,\n        'predicted_vit_stat_int': predicted_vit_stat_int_test\n    })\n    test_df = pd.merge(test_df, pred_df, on='record_id', how='left')\n\n    # Merge predictions into test_real1s_df\n    test_real1s_df['record_id'] = test_real1s_df['record_id'].astype(int)\n    test_real1s_dataset_record_ids = [int(rid) for rid in test_dataset_real1s['record_id']]\n    pred_real1s_df = pd.DataFrame({\n        'record_id': test_real1s_dataset_record_ids,\n        'predicted_vit_stat_int': predicted_vit_stat_int_real1s\n    })\n    test_real1s_df = pd.merge(test_real1s_df, pred_real1s_df, on='record_id', how='left')\n\n    # Define columns to exclude\n    columns_to_exclude = ['input_ids', 'token_type_ids', 'attention_mask', 'regression_prompt', 'labels']\n\n    # Drop unnecessary columns\n    train_df = train_df.drop(columns=[col for col in columns_to_exclude if col in train_df.columns])\n    eval_full_df = eval_full_df.drop(columns=[col for col in columns_to_exclude if col in eval_full_df.columns])\n    test_df = test_df.drop(columns=[col for col in columns_to_exclude if col in test_df.columns])\n    test_real1s_df = test_real1s_df.drop(columns=[col for col in columns_to_exclude if col in test_real1s_df.columns])\n\n    # Save datasets and metrics to Excel\n    with pd.ExcelWriter(filename, engine='xlsxwriter') as writer:\n        # Save regression metrics\n        metrics_df.to_excel(writer, sheet_name=\"Regression Metrics\", index=False)\n\n        # Save train data\n        train_df.to_excel(writer, sheet_name=\"Train Data\", index=False)\n\n        # Save eval data\n        eval_full_df.to_excel(writer, sheet_name=\"Eval Data\", index=False)\n\n        # Save test data with predictions\n        test_df.to_excel(writer, sheet_name=\"Test Data Predicted 1s\", index=False)\n\n        # Save test_real1s data with predictions\n        test_real1s_df.to_excel(writer, sheet_name=\"Test Data True Positives\", index=False)\n\n    print(f\"Regression metrics and data have been saved to '{filename}'.\")","metadata":{"_uuid":"b485a8c0-6d75-45b6-bf10-80e8942f3ea2","_cell_guid":"e5e306f4-0708-4676-b075-1d25a1e63c2d","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-11-12T16:23:32.972131Z","iopub.status.idle":"2024-11-12T16:23:32.972471Z","shell.execute_reply.started":"2024-11-12T16:23:32.972297Z","shell.execute_reply":"2024-11-12T16:23:32.972314Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"save_regression_metrics_to_excel(\n    train_dataset=split_train_data_regression,\n    eval_dataset=eval_data,\n    test_dataset=test_data_regression,\n    test_dataset_real1s=test_data_regression_real1s,\n    predicted_vit_stat_int_test=predicted_vit_stat_int_test,\n    predicted_vit_stat_int_real1s=predicted_vit_stat_int_real1s\n)","metadata":{"_uuid":"da7d4aec-dd87-46c9-9330-6647738c92c1","_cell_guid":"59c3494c-0e8f-480a-ba02-a4e1769e5ce8","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-11-12T16:23:32.973331Z","iopub.status.idle":"2024-11-12T16:23:32.973665Z","shell.execute_reply.started":"2024-11-12T16:23:32.973498Z","shell.execute_reply":"2024-11-12T16:23:32.973515Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null}]}